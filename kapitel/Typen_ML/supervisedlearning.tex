Der Grundgedanke bei supervised Learning ist, dass die Beispiele (Ein- und
Ausgabewerte) bekannt sind. Die Aufgabe des Computers gleicht hier dem
Auswendiglernen, wobei der Rechner dies deutlich einfacher und schneller
schafft als Menschen. Hieraus ergibt sich eine Funktion, mit welcher bei
unbekannten Eingabewerten eine sinnvolle Ausgabe erzielt wird. Diese Funktion
wird in der künstlichen Intelligenz als Modell bezeichnet. Die Entwicklung des
Modells ist ein stetiger Prozess. Die Parameter des Modells werden während der
Lernphase immer wieder angepasst, um die Optimalen Werte hierfür zu finden. Der
besondere Vorteil am überwachten Lernen liegt darin, dass man die Ausgaben
kennt, und somit während des Lernvorgangs das Modell hinsichtlich der
Fehleranfälligkeit überprüfen kann. Bewertet wird das Modell dann jedoch mit
Daten, die noch nicht bekannt sind, wobei man möglichst versucht, zu vermeiden,
eine höhere Fehleranzahl zu haben, als in der Lernphase, genannt Overfitting.
Auch Underfitting stellt ein Problem dar, was meist der Fall ist, wenn die
Komplexität eines Modells zu niedrig ist.\cite{lanquillon2019grundzuge}\\ 
Man unterscheidet hierbei zwischen konkreten Ausgabewerten, sowie kontinuierliche
Werte. Diese beiden Wertearten bestimmen, ob es sich bei dem
supervised-learning Ansatz um eine Klassifikation oder eine Regression handelt.
Bei einem kontinuierlichen Ausgangstyp ist es eine Regression, bei einem
diskreten Ausgabewert spricht man von einer Klassifikation. Diese
Unterscheidung ist nur von den Ausgabetypen abhängig und nicht von den
Eingabewerten.\cite{matzka2021unuberwachtes}\\